# 图形处理单元

[TOC]

## 引言

从颜色插值，显示到访问纹理数据，内建的`z-depth`可见性检查，越来越多的加速特性被添加到图形硬件中。专用的加速图形硬件和CPU相比的优势只在于速度，而速度对于图形处理来说是至关重要的。

在过去的二十年期间，图形硬件发生了巨大的变化。从固定功能管线，可配置管线到高度可编程管线，开发者可以更灵活的实现他们的算法。尽管出于效率上的考虑，管线的某些部分仍是可配置而不是可编程的，但总体的趋势朝着可编程性和灵活性迈进。

为了显著提升速度，GPU在高度可并行任务上做了相当的优化。比如，使用了定制的芯片来实现`z-buffer`,快速访问纹理，光栅化等等。下面的章节将会告诉你GPU怎么为可编程着色器实现平行化。

现在，只需要知道一个着色器核心(`shader core`)是一个小的处理器，它可以执行一些相对独立的任务，比如坐标转换。在图形处理的每帧中，有成千上万的三角形被发送到屏幕上，同时每秒也会激活上百万的着色器(`shader`)，也就是说，会产生同样数量的独立运行着色程序的实例。

首先，延迟(`latency`)是需要处理单元都需要面临的问题。简单来说，信息离处理单元越远，延迟越高。比如，访问内存上的数据就比寄存器的延迟高得多。要明白的一点是，由于等待数据取回造成的延迟会使得处理器被堵塞(`stalled`)，从而降低性能。

## 数据并行架构

不同的处理器架构采用不同的策略来避免拥堵。CPU被优化于处理种类广泛的数据结构和大规模的代码。尽管CPU可以有多个处理器，但每个处理器几乎是串行的运行代码，大大限制了`SIMD`的能力。

GPU采用不同的优化方法。GPU通常拥有大量的处理单元，也就是所谓的着色器核心(`shader core`)。GPU是一个流处理器，可以轮流的处理一系列相似的数据。由于数据的相似性（顶点/像素），GPU可以以大规模并行的方式去处理它们。一个关键的要素是调用要尽可能独立，数据之间不共享，否则会造成额外的延迟。

GPU专门为流量`throughput`进行优化，以尽可能快的处理更多数据。然而，由于更小的芯片面积限制，单个GPU的缓存和控制逻辑能力比CPU弱的多，因而对每个着色器核心来说，延迟问题也更加突出。

举个例子，当有两千个顶点需要着色时，假设GPU只有一个着色器核心，那么一个片元着色器会被调用两千次。当着色器需要执行譬如纹理获取的耗时操作时，就会被堵塞而不进行任何操作。

## GPU管线概览

## 可编程着色阶段

## 可编程着色和API的发展

## 顶点着色器

## 细分阶段

## 几何着色器

## 像素着色器

## 合并阶段

## 计算着色器
 